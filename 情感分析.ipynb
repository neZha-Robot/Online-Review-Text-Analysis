{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体书写参考https://zhuanlan.zhihu.com/p/394021335\n",
    "的3.2 基于属性的细粒度情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T09:45:37.753356Z",
     "iopub.status.busy": "2023-03-29T09:45:37.752781Z",
     "iopub.status.idle": "2023-03-29T09:46:04.629062Z",
     "shell.execute_reply": "2023-03-29T09:46:04.628136Z",
     "shell.execute_reply.started": "2023-03-29T09:45:37.753322Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格的情感倾向为：0.84\r\n",
      "口感的情感倾向为：0.97\r\n",
      "服务的情感倾向为：0.65\r\n",
      "物流的情感倾向为：0.66\r\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from snownlp import SnowNLP\n",
    "import pandas as pd\n",
    "# 主题词典\n",
    "topic_dict = {\"价格\": [\"便宜\", \"贵\", \"优惠\", \"划算\"],\n",
    "              \"口感\": [\"好吃\", \"难吃\", \"美味\"],\n",
    "              \"服务\": [\"态度\", \"热情\", \"周到\"],\n",
    "              \"物流\": [\"物流\", \"快\"]}\n",
    "# 提取评论中的句子\n",
    "def extract_sentences(text):\n",
    "    # 将文本分为句子\n",
    "    sentences = re.split(r'[。！？]', text)\n",
    "    # 去除空句子\n",
    "    sentences = [sent.strip() for sent in sentences if len(sent.strip()) > 0]\n",
    "    return sentences\n",
    "# 匹配主题词\n",
    "def match_topic(sentence, topic_dict):\n",
    "    # 初始化主题词\n",
    "    topic = None\n",
    "    # 遍历主题词典\n",
    "    for t, attributes in topic_dict.items():\n",
    "        # 判断主题词是否在句子中\n",
    "        if t in sentence:\n",
    "            topic = t\n",
    "            break\n",
    "    return topic\n",
    "# 读取评论数据\n",
    "df = pd.read_excel(\"new_new_寺库.xlsx\")\n",
    "# 对主题词进行情感分析\n",
    "for topic in topic_dict:\n",
    "    topic_sentiments = []\n",
    "    for comment in df[\"comment\"]:\n",
    "        # 分句\n",
    "        sentences = extract_sentences(comment)\n",
    "        # 遍历句子\n",
    "        for sentence in sentences:\n",
    "            # 匹配主题词\n",
    "            if match_topic(sentence, topic_dict) == topic:\n",
    "                # 进行情感分析\n",
    "                s = SnowNLP(sentence)\n",
    "                sentiment = s.sentiments\n",
    "                topic_sentiments.append(sentiment)\n",
    "    # 输出主题词情感分析结果\n",
    "    if len(topic_sentiments) > 0:\n",
    "        avg_sentiment = sum(topic_sentiments) / len(topic_sentiments)\n",
    "        print(f\"{topic}的情感倾向为：{avg_sentiment:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T09:49:55.794489Z",
     "iopub.status.busy": "2023-03-29T09:49:55.793949Z",
     "iopub.status.idle": "2023-03-29T09:50:07.196041Z",
     "shell.execute_reply": "2023-03-29T09:50:07.194790Z",
     "shell.execute_reply.started": "2023-03-29T09:49:55.794456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格的情感倾向为：0.81\r\n",
      "服务的情感倾向为：0.67\r\n",
      "物流的情感倾向为：0.82\r\n"
     ]
    }
   ],
   "source": [
    "import re\r\n",
    "from snownlp import SnowNLP\r\n",
    "import pandas as pd\r\n",
    "# 主题词典\r\n",
    "topic_dict = {\"价格\": [\"便宜\", \"贵\", \"优惠\", \"划算\"],\r\n",
    "              \"口感\": [\"好吃\", \"难吃\", \"美味\"],\r\n",
    "              \"服务\": [\"态度\", \"热情\", \"周到\"],\r\n",
    "              \"物流\": [\"物流\", \"快\"]}\r\n",
    "# 提取评论中的句子\r\n",
    "def extract_sentences(text):\r\n",
    "    # 将文本分为句子\r\n",
    "    sentences = re.split(r'[。！？]', text)\r\n",
    "    # 去除空句子\r\n",
    "    sentences = [sent.strip() for sent in sentences if len(sent.strip()) > 0]\r\n",
    "    return sentences\r\n",
    "# 匹配主题词\r\n",
    "def match_topic(sentence, topic_dict):\r\n",
    "    # 初始化主题词\r\n",
    "    topic = None\r\n",
    "    # 遍历主题词典\r\n",
    "    for t, attributes in topic_dict.items():\r\n",
    "        # 判断主题词是否在句子中\r\n",
    "        if t in sentence:\r\n",
    "            topic = t\r\n",
    "            break\r\n",
    "    return topic\r\n",
    "# 读取评论数据\r\n",
    "df = pd.read_excel(\"new_new_data_京东.xlsx\")\r\n",
    "# 对主题词进行情感分析\r\n",
    "for topic in topic_dict:\r\n",
    "    topic_sentiments = []\r\n",
    "    for comment in df[\"comment\"]:\r\n",
    "        # 分句\r\n",
    "        sentences = extract_sentences(comment)\r\n",
    "        # 遍历句子\r\n",
    "        for sentence in sentences:\r\n",
    "            # 匹配主题词\r\n",
    "            if match_topic(sentence, topic_dict) == topic:\r\n",
    "                # 进行情感分析\r\n",
    "                s = SnowNLP(sentence)\r\n",
    "                sentiment = s.sentiments\r\n",
    "                topic_sentiments.append(sentiment)\r\n",
    "    # 输出主题词情感分析结果\r\n",
    "    if len(topic_sentiments) > 0:\r\n",
    "        avg_sentiment = sum(topic_sentiments) / len(topic_sentiments)\r\n",
    "        print(f\"{topic}的情感倾向为：{avg_sentiment:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T09:50:58.064899Z",
     "iopub.status.busy": "2023-03-29T09:50:58.063802Z",
     "iopub.status.idle": "2023-03-29T09:50:59.842550Z",
     "shell.execute_reply": "2023-03-29T09:50:59.841634Z",
     "shell.execute_reply.started": "2023-03-29T09:50:58.064852Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "价格的情感倾向为：0.79\r\n",
      "服务的情感倾向为：0.83\r\n",
      "物流的情感倾向为：0.83\r\n"
     ]
    }
   ],
   "source": [
    "import re\r\n",
    "from snownlp import SnowNLP\r\n",
    "import pandas as pd\r\n",
    "# 主题词典\r\n",
    "topic_dict = {\"价格\": [\"便宜\", \"贵\", \"优惠\", \"划算\"],\r\n",
    "              \"口感\": [\"好吃\", \"难吃\", \"美味\"],\r\n",
    "              \"服务\": [\"态度\", \"热情\", \"周到\"],\r\n",
    "              \"物流\": [\"物流\", \"快\"]}\r\n",
    "# 提取评论中的句子\r\n",
    "def extract_sentences(text):\r\n",
    "    # 将文本分为句子\r\n",
    "    sentences = re.split(r'[。！？]', text)\r\n",
    "    # 去除空句子\r\n",
    "    sentences = [sent.strip() for sent in sentences if len(sent.strip()) > 0]\r\n",
    "    return sentences\r\n",
    "# 匹配主题词\r\n",
    "def match_topic(sentence, topic_dict):\r\n",
    "    # 初始化主题词\r\n",
    "    topic = None\r\n",
    "    # 遍历主题词典\r\n",
    "    for t, attributes in topic_dict.items():\r\n",
    "        # 判断主题词是否在句子中\r\n",
    "        if t in sentence:\r\n",
    "            topic = t\r\n",
    "            break\r\n",
    "    return topic\r\n",
    "# 读取评论数据\r\n",
    "df = pd.read_excel(\"new_new_data_唯品会.xlsx\")\r\n",
    "# 对主题词进行情感分析\r\n",
    "for topic in topic_dict:\r\n",
    "    topic_sentiments = []\r\n",
    "    for comment in df[\"comment\"]:\r\n",
    "        # 分句\r\n",
    "        sentences = extract_sentences(comment)\r\n",
    "        # 遍历句子\r\n",
    "        for sentence in sentences:\r\n",
    "            # 匹配主题词\r\n",
    "            if match_topic(sentence, topic_dict) == topic:\r\n",
    "                # 进行情感分析\r\n",
    "                s = SnowNLP(sentence)\r\n",
    "                sentiment = s.sentiments\r\n",
    "                topic_sentiments.append(sentiment)\r\n",
    "    # 输出主题词情感分析结果\r\n",
    "    if len(topic_sentiments) > 0:\r\n",
    "        avg_sentiment = sum(topic_sentiments) / len(topic_sentiments)\r\n",
    "        print(f\"{topic}的情感倾向为：{avg_sentiment:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6922a9521a6ee1ce7f8c1dd0f269e02385237cdfa43bf19c0dcc609bd325874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
